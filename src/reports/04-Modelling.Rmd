---
title: "04 Modeling"
date: "`r Sys.time()`"
author: Sebastian Sauer
params:
  dataset: dataset
output: 
  html_document:
    number_sections: TRUE
    toc: TRUE
editor_options: 
  chunk_output_type: console
---


# Setup


```{r global-knitr-options, include=FALSE}

knitr::opts_chunk$set(
  fig.pos = 'H',
  fig.asp = 0.618,
  fig.align='center',
  fig.width = 5,
  out.width = "100%",
  fig.cap = "", 
  fig.path = "chunk-img/",
  dpi = 300,
  # tidy = TRUE,
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  cache = FALSE,
  fig.show = "hold")
```



```{r load-libs}
library("tidyverse")
library("here")
library("assertthat")
library("tidymodels")
library("xgboost")
library("tictoc")
library("gt")
library("vip")
library("futile.logger")
```



```{r general-setup}
tidymodels_prefer() 
conflicted::conflict_prefer("spec", "yardstick")
conflicted::conflict_prefer("discard", "purrr")

source(here("src", "01-constants.R"))

cores <- parallel::detectCores()
doParallel::registerDoParallel()
```



# Init logger

```{r init-logger, echo = FALSE}
flog.appender(appender.file("covid-icu.log"))
flog.threshold(INFO)
flog.info("STARTING script 04: Modelling")
flog.info("Logger inited")
```

# Train and Test





**Dataset used: `r dataset`**

**Dataset path:** `r data_processed_path`

## Import data

```{r prepare-data, results = "hide", message = FALSE, warning = FALSE}
stopifnot(file.exists(data_processed_path))

d <- read_csv(data_processed_path)
flog.info("Processed data was read.")
flog.info(paste0("Dimensions of data set read are: ", str_c(dim(d), collapse = ", ")))
flog.info(paste0("Data path: ", data_processed_path))
```


Dimensions of the data set:

```{r}
dim(d)
```


## DV as factor

Define DV as factor, since we are modelling a *classification setting*:

```{r}
d <-
  d %>% 
  mutate(verlauf = factor(verlauf))
```



## Check

### NA per column/variable

List of columns with missing values

```{r}
d %>% 
  map_dfr( ~ sum(is.na(.))) %>% 
  pivot_longer(everything()) %>% 
  arrange(-value) %>% 
  filter(value > 0) %>% 
  gt()
```


Number of observations when all NAs (in all columns) are removed:

```{r}
d %>% 
  drop_na() %>% 
  nrow()
```



## Splitting

    
```{r}
set.seed(42)
d_split <- initial_split(d, prop = .8, strata = verlauf)
d_split
```



```{r}
d_train <- training(d_split)
d_test <- training(d_split)
```



# Define workflow


## Models

### Majority model

```{r}
d_train %>% 
  count(verlauf) %>% 
  mutate(verlauf_prop = n/sum(n)) %>% 
  gt() %>% 
  fmt_number(where(is.numeric))
```

Hence, the **Accuracy** performance measure in this model is
the larger value of the proportion.



### XGB

```{r xgb-mod}
xgb_mod <- 
  boost_tree(
  trees = 1000, 
  tree_depth = tune(), 
  min_n = tune(), 
  loss_reduction = tune(),  ## first three: model complexity
  sample_size = tune(), mtry = tune(), ## randomness
  learn_rate = tune(),  ## step size
) %>% 
  set_engine("xgboost") %>% 
  set_mode("classification")
```


### RF

```{r rf-mod}
rf_mod <- 
  rand_forest(mtry = tune(), 
              min_n = tune(), 
              trees = 1000) %>% 
  set_engine("ranger", 
             num.threads = cores, 
             importance = "permutation") %>% 
  set_mode("classification")
```



### Logistic regression

```{r glm-mod}
logistic_mod <-
  logistic_reg()  # engine is set by default
```


## CV

10 folds, 3 repeats.

```{r}
folds_spec <-
  vfold_cv(d_train, repeats  = 3)
```



## Recipe

```{r}
basic_recipe <-
  recipe(verlauf ~ ., data = d_train) %>% 
  update_role(id, new_role = "ID") %>% 
  update_role(all_of(forbidden_vars), new_role = "ID") %>% 
  step_zv(all_numeric(), -all_outcomes()) %>% 
  step_normalize(all_numeric(), -all_outcomes()) %>% 
  step_corr(all_predictors(), threshold = 0.7, method = "spearman") %>% 
  step_impute_knn(all_predictors())
```


## Workflows


```{r xgb-wf}
xgb_wf <-
  workflow() %>% 
  add_model(xgb_mod) %>% 
  add_recipe(basic_recipe)
```



```{r rf-wf}
rf_wf <-
  workflow() %>% 
  add_model(rf_mod) %>% 
  add_recipe(basic_recipe)

rf_wf
```



```{r}
logistic_wf <-
  workflow() %>% 
  add_model(logistic_mod) %>% 
  add_recipe(basic_recipe)
```



## Define performance metrics


```{r}
class_metrics <- 
  metric_set(
      recall, 
      precision, 
      f_meas, 
      accuracy, 
      kap,
      roc_auc, 
      sens, 
      spec,
      ppv
  )
```



## Fit resamples/tune

### XGB 


```{r}
xgb_grid <- 
  grid_latin_hypercube(
    tree_depth(),
    min_n(),
    loss_reduction(),
    sample_size = sample_prop(),
    finalize(mtry(), d_train),
    learn_rate(),
    size = 30
  )
```


```{r grid-xgb}
doParallel::registerDoParallel()

if (rerun_all == FALSE & file.exists(xgb01_outputfile)){
  xgb_res <- read_rds(file = xgb01_outputfile)
} else {
  tic()
  cat("Computing XGB with tuning grid\n")
  xgb_res <-
    xgb_wf %>% 
    tune_grid(
      xgb_wf,
      resamples = folds_spec,
      metrics = metric_set(
        recall, 
        precision, 
        f_meas, 
        accuracy, 
        kap,
        roc_auc, 
        sens, 
        spec,
        ppv
  ),
      grid = xgb_grid,
      control = control_grid(save_pred = TRUE)
    )
  toc()
  write_rds(xgb_res, file = xgb01_outputfile)
} 
```

### RF



```{r}
rf_mod
```

```{r grid-rf}
if (rerun_all == FALSE & file.exists(rf01_outputfile)){
  flog.info("Reading RDS file for Random Forest 01 model.")
  rf_res <- read_rds(file = rf01_outputfile)
} else {
  flog.info("Computing Random Forest 01 model.")
  tic()
  cat("Computing RF with tuning grid\n")
  rf_res <-
    rf_wf %>% 
    tune_grid(
      resamples = folds_spec,
      grid = 25,
      control = control_grid(save_pred = TRUE),
      metrics = metric_set(
        recall, 
        precision, 
        f_meas, 
        accuracy, 
        kap,
        roc_auc, 
        sens, 
        spec,
        ppv
  ))
  toc()
  write_rds(rf_res, file = rf01_outputfile)
}
```

### Logistic regression

```{r fit-logistic-regr}
logistic_res <-
  logistic_wf %>% 
   fit_resamples(
      resamples = folds_spec,
      control = control_grid(save_pred = TRUE),
      metrics = metric_set(
        recall, 
        precision, 
        f_meas, 
        accuracy, 
        kap,
        roc_auc, 
        sens, 
        spec,
        ppv
  ))

write_rds(logistic_res, file = logistic01_outputfile)
```



# Results

First, let's check the performance in the resamples and
see which model candidates performed best.

## XGB


Let's have a look at the results:


```{r}
xgb_res %>% 
  collect_metrics(summarize = TRUE) %>% 
  slice_head(n = 10) %>% 
  gt() %>% 
  fmt_number(where(is.numeric)) 
```



```{r out.height=10, fig.asp = 1}
autoplot(xgb_res)

if (write_to_disk) ggsave(filename = paste0(figs_prefix_path, "xgb_res_cv.pdf"), 
       width = 10, height = 10)
```


```{r}
show_best(xgb_res)
```



## RF


```{r}
rf_res %>% 
  collect_metrics(summarize = TRUE) %>% 
  slice_head(n = 10) %>% 
  gt() %>% 
  fmt_number(where(is.numeric))
```


```{r out.height=10, fig.asp = 1}
autoplot(rf_res)

if (write_to_disk) ggsave(filename = paste0(figs_prefix_path, "rf_res_cv.pdf"), 
       width = 10, height = 10)
```


```{r}
show_best(rf_res)
```


## Logistic Regression


```{r}
logistic_res %>% 
  collect_metrics(summarize = TRUE) %>% 
  gt() %>% 
  fmt_number(where(is.numeric))
```




```{r}
show_best(logistic_res)
```



# Best tuning parameters

## RF

```{r}
show_best(rf_res, metric = "recall")
select_best(rf_res, metric = "recall")

rf_best_params <-
  tibble(
    mtry = select_best(rf_res, metric = "recall")$mtry[1],
    min_n = select_best(rf_res, metric = "recall")$min_n[1]
  )
```




### Finalize workflow

```{r}
fin_rf_wf <-
  rf_wf %>% 
  finalize_workflow(rf_best_params)
fin_rf_wf
```



### Final fit

```{r}
final_rf_fit <-
  fin_rf_wf %>% 
  last_fit(d_split,
           metrics = metric_set(
             recall, 
             precision, 
             f_meas, 
             accuracy, 
             kap,
             roc_auc, 
             sens, 
             spec,
             ppv)
  )

final_rf_fit
```

Check the notes:

```{r}
final_rf_fit %>% pluck(".notes", 1) %>% pull(3)
```




```{r}
if (write_to_disk == TRUE) 
  write_rds(final_rf_fit, 
            file = final_rf_fit_file)
```



### Get performance metrics





```{r}
final_fit_metrics_rf <- 
  final_rf_fit %>% 
  collect_metrics()

final_fit_metrics_rf
```


```{r}
final_fit_metrics_rf %>% 
  select(-.config) %>% 
  gt() %>% 
  fmt_number(where(is.numeric))
```



```{r}
final_rf_fit %>% 
  pluck(".workflow", 1) %>% 
  extract_fit_parsnip() %>% 
  vip(num_features = 20)
```




# Baseline model for Accuracy


```{r}
d %>% 
  count(verlauf) %>% 
  mutate(prop = n/sum(n)) %>% 
  gt() %>% 
  fmt_number(3)
```

